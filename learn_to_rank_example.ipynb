{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "933ea0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Ranking module also shared as a gist: https://gist.github.com/ceroper/58675b2ac2c73b66f24f63c32e837af2\n",
    "from ranking import *\n",
    "from ranksvm_utils import *\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.datasets import load_svmlight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7656af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloaded Learn to Rank dataset here: https://huggingface.co/datasets/YahooResearch/Yahoo-Learning-to-Rank-Challenge\n",
    "# Found \"convert\" function source here: https://colab.research.google.com/github/finardi/tutos/blob/master/learning_to_rank.ipynb/#scrollTo=vmpCW_oepNCZ\n",
    "## Note that we have convert the original raw data into a pure libsvm format.\n",
    "## For more details, pls refer to: https://github.com/guolinke/boosting_tree_benchmarks/tree/master/data\n",
    "\n",
    "def convert(input_filename, out_data_filename, out_query_filename, out_query_filename2):\n",
    "\tinput = open(input_filename,\"r\")\n",
    "\toutput_feature = open(out_data_filename,\"w\")\n",
    "\toutput_query = open(out_query_filename,\"w\")\n",
    "\toutput_query2 = open(out_query_filename2,\"w\")\n",
    "\tcur_cnt = 0\n",
    "\tcur_doc_cnt = 0\n",
    "\tlast_qid = -1\n",
    "\twhile True:\n",
    "\t\tline = input.readline()\n",
    "\t\tif not line:\n",
    "\t\t\tbreak\n",
    "\t\ttokens = line.split(' ')\n",
    "\t\ttokens[-1] = tokens[-1].strip()\n",
    "\t\tlabel = tokens[0]\n",
    "\t\tqid = int(tokens[1].split(':')[1])\n",
    "\t\tif qid != last_qid:\n",
    "\t\t\tif cur_doc_cnt > 0:\n",
    "\t\t\t\toutput_query.write(str(cur_doc_cnt) + '\\n')\n",
    "\t\t\t\toutput_query2.write(str(cur_doc_cnt) + '\\n')\n",
    "\t\t\t\tcur_cnt += 1\n",
    "\t\t\tcur_doc_cnt = 0\n",
    "\t\t\tlast_qid = qid\n",
    "\t\tcur_doc_cnt += 1\n",
    "\t\toutput_feature.write(label+' ')\n",
    "\t\toutput_feature.write(' '.join(tokens[2:]) + '\\n')\n",
    "\toutput_query.write(str(cur_doc_cnt) + '\\n')\n",
    "\toutput_query2.write(str(cur_doc_cnt) + '\\n')\n",
    "\t\n",
    "\tinput.close()\n",
    "\toutput_query.close()\n",
    "\toutput_feature.close()\n",
    "\toutput_query2.close()\n",
    "\n",
    "convert(\"Learning to Rank Challenge/ltrc_yahoo/set1.train.txt\",\"yahoo.train\",\"yahoo.train.query\",\"yahoo.train.group\")\n",
    "convert(\"Learning to Rank Challenge/ltrc_yahoo/set1.test.txt\",\"yahoo.test\",\"yahoo.test.query\",\"yahoo.test.group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e5a9b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the LIBSVM file\n",
    "X, y = load_svmlight_file('yahoo.train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7075f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the LIBSVM file\n",
    "g = load_svmlight_file('yahoo.train.group')\n",
    "groups = g[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbf43688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the groups variable with this code to convert group sizes to group IDs\n",
    "group_ids = [group_num for group_num, count in enumerate([int(x) for x in groups], start=1) for _ in range(count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f621717",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_groups = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab0ce088",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len([x for x in group_ids if x <= max_groups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f84f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:n].toarray()\n",
    "y = y[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a8ff2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_ids = [x for x in group_ids if x <= max_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2b19caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2 = np.concatenate(\n",
    "    (y[:, np.newaxis], np.array(group_ids)[:, np.newaxis]),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01a3e9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6176, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4b00a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=3)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 10],\n",
    "    'max_iter': [1000, 5000],\n",
    "    'tol': [1e-4],\n",
    "    'penalty': ['l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e305ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 NDCG: 0.8717\n",
      "Fold 2 NDCG: 0.8056\n",
      "Fold 3 NDCG: 0.7147\n",
      "folds complete {'C': 0.1, 'tol': 0.0001, 'max_iter': 1000, 'penalty': 'l2', 'scores': [np.float64(0.8717100107511292), np.float64(0.8056127579149828), np.float64(0.7146759081994981)], 'mean_score': np.float64(0.7973328922885367)}\n",
      "Fold 1 NDCG: 0.8717\n",
      "Fold 2 NDCG: 0.8056\n",
      "Fold 3 NDCG: 0.7147\n",
      "folds complete {'C': 0.1, 'tol': 0.0001, 'max_iter': 5000, 'penalty': 'l2', 'scores': [np.float64(0.8717100107511292), np.float64(0.8056127579149828), np.float64(0.7146759081994981)], 'mean_score': np.float64(0.7973328922885367)}\n",
      "Fold 1 NDCG: 0.8717\n",
      "Fold 2 NDCG: 0.8056\n",
      "Fold 3 NDCG: 0.7147\n",
      "folds complete {'C': 10, 'tol': 0.0001, 'max_iter': 1000, 'penalty': 'l2', 'scores': [np.float64(0.8717100107511292), np.float64(0.8056127579149828), np.float64(0.7146759081994981)], 'mean_score': np.float64(0.7973328922885367)}\n",
      "Fold 1 NDCG: 0.8717\n",
      "Fold 2 NDCG: 0.8056\n",
      "Fold 3 NDCG: 0.7147\n",
      "folds complete {'C': 10, 'tol': 0.0001, 'max_iter': 5000, 'penalty': 'l2', 'scores': [np.float64(0.8717100107511292), np.float64(0.8056127579149828), np.float64(0.7146759081994981)], 'mean_score': np.float64(0.7973328922885367)}\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "scores = []\n",
    "\n",
    "for penalty in param_grid['penalty']:\n",
    "    for c in param_grid['C']:\n",
    "        for max_iter in param_grid['max_iter']:\n",
    "            for tol in param_grid['tol']:\n",
    "                fold_scores = []\n",
    "                for fold_idx, (train_idx, val_idx) in enumerate(gkf.split(X, y_2, group_ids)):\n",
    "\n",
    "                    # Get training and validation DataFrames\n",
    "                    X_train_fold = X[train_idx].copy()\n",
    "                    y_train_fold = y_2[train_idx].copy()\n",
    "                    X_val_fold = X[val_idx].copy()\n",
    "                    X_val_fold = np.concatenate((X_val_fold, np.array(group_ids)[val_idx][:, np.newaxis]), axis=1)\n",
    "                    y_val_fold = y_2[val_idx].copy()\n",
    "                    \n",
    "                    # Create DataFrame for easier handling with session_id\n",
    "                    y_val_df_eval = pd.DataFrame({\n",
    "                        'label': y_val_fold[:, 0],\n",
    "                        'group': y_val_fold[:, 1]\n",
    "                    })\n",
    "\n",
    "                    # Fit and evaluate using calculate_ranking_ndcg\n",
    "                    fold_model = RankSVM(C=c, tol=tol, max_iter=max_iter, penalty=penalty, dual=False, random_state=42)\n",
    "                    fold_model.fit(X_train_fold, y_train_fold)\n",
    "                    preds = fold_model.predict(X_val_fold)\n",
    "                    y_val_df_eval['y_pred'] = preds\n",
    "                    fold_score = calculate_ranking_ndcg(y_val_df_eval.label,\n",
    "                                                       y_val_df_eval.y_pred,\n",
    "                                                       get_group_sizes(y_val_df_eval))\n",
    "\n",
    "                    fold_scores.append(fold_score)\n",
    "                    print(f\"Fold {fold_idx + 1} NDCG: {fold_score:.4f}\")\n",
    "                res = {'C': c, 'tol': tol, 'max_iter': max_iter, 'penalty':penalty, 'scores':fold_scores, 'mean_score':np.mean(fold_scores)}\n",
    "                results.append(res)\n",
    "                print ('folds complete', res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ranksvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
