{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933ea0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Ranking module also shared as a gist: https://gist.github.com/ceroper/58675b2ac2c73b66f24f63c32e837af2\n",
    "from ranking import *\n",
    "from utils import *\n",
    "from sklearn import svm, linear_model\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7656af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloaded Learn to Rank dataset here: https://huggingface.co/datasets/YahooResearch/Yahoo-Learning-to-Rank-Challenge\n",
    "# Found \"convert\" function source here: https://colab.research.google.com/github/finardi/tutos/blob/master/learning_to_rank.ipynb/#scrollTo=vmpCW_oepNCZ\n",
    "## Note that we have convert the original raw data into a pure libsvm format.\n",
    "## For more details, pls refer to: https://github.com/guolinke/boosting_tree_benchmarks/tree/master/data\n",
    "\n",
    "def convert(input_filename, out_data_filename, out_query_filename, out_query_filename2):\n",
    "\tinput = open(input_filename,\"r\")\n",
    "\toutput_feature = open(out_data_filename,\"w\")\n",
    "\toutput_query = open(out_query_filename,\"w\")\n",
    "\toutput_query2 = open(out_query_filename2,\"w\")\n",
    "\tcur_cnt = 0\n",
    "\tcur_doc_cnt = 0\n",
    "\tlast_qid = -1\n",
    "\twhile True:\n",
    "\t\tline = input.readline()\n",
    "\t\tif not line:\n",
    "\t\t\tbreak\n",
    "\t\ttokens = line.split(' ')\n",
    "\t\ttokens[-1] = tokens[-1].strip()\n",
    "\t\tlabel = tokens[0]\n",
    "\t\tqid = int(tokens[1].split(':')[1])\n",
    "\t\tif qid != last_qid:\n",
    "\t\t\tif cur_doc_cnt > 0:\n",
    "\t\t\t\toutput_query.write(str(cur_doc_cnt) + '\\n')\n",
    "\t\t\t\toutput_query2.write(str(cur_doc_cnt) + '\\n')\n",
    "\t\t\t\tcur_cnt += 1\n",
    "\t\t\tcur_doc_cnt = 0\n",
    "\t\t\tlast_qid = qid\n",
    "\t\tcur_doc_cnt += 1\n",
    "\t\toutput_feature.write(label+' ')\n",
    "\t\toutput_feature.write(' '.join(tokens[2:]) + '\\n')\n",
    "\toutput_query.write(str(cur_doc_cnt) + '\\n')\n",
    "\toutput_query2.write(str(cur_doc_cnt) + '\\n')\n",
    "\t\n",
    "\tinput.close()\n",
    "\toutput_query.close()\n",
    "\toutput_feature.close()\n",
    "\toutput_query2.close()\n",
    "\n",
    "convert(\"Learning to Rank Challenge/ltrc_yahoo/set1.train.txt\",\"yahoo.train\",\"yahoo.train.query\",\"yahoo.train.group\")\n",
    "convert(\"Learning to Rank Challenge/ltrc_yahoo/set1.test.txt\",\"yahoo.test\",\"yahoo.test.query\",\"yahoo.test.group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e5a9b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the LIBSVM file\n",
    "X, y = load_svmlight_file('yahoo.train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7075f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the LIBSVM file\n",
    "g = load_svmlight_file('yahoo.train.group')\n",
    "groups = g[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbf43688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the groups variable with this code to convert group sizes to group IDs\n",
    "group_ids = [group_num for group_num, count in enumerate([int(x) for x in groups], start=1) for _ in range(count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f621717",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_groups = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab0ce088",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len([x for x in group_ids if x <= max_groups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f84f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:n].toarray()\n",
    "y = y[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a8ff2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_ids = [x for x in group_ids if x <= max_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66d97e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_2 = np.concatenate(\n",
    "    (X, np.array(group_ids)[:, np.newaxis]),\n",
    "    axis=1\n",
    ")\n",
    "y_2 = np.concatenate(\n",
    "    (y[:, np.newaxis], np.array(group_ids)[:, np.newaxis]),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4b00a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 100],\n",
    "    'max_iter': [1000, 5000],\n",
    "    'tol': [1e-4],\n",
    "    'penalty': ['l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4506892f",
   "metadata": {},
   "source": [
    "Example Cross-Validating the Pairwise Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e305ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 NDCG: 0.8094\n",
      "Fold 2 NDCG: 0.4878\n",
      "Fold 3 NDCG: 0.9727\n",
      "Fold 4 NDCG: 0.8350\n",
      "Fold 5 NDCG: 0.8016\n",
      "folds complete {'C': 0.01, 'tol': 0.0001, 'max_iter': 1000, 'penalty': 'l2', 'scores': [np.float64(0.8094), np.float64(0.4878), np.float64(0.9727), np.float64(0.835), np.float64(0.8016)], 'mean_score': np.float64(0.7813)}\n",
      "Fold 1 NDCG: 0.8094\n",
      "Fold 2 NDCG: 0.4878\n",
      "Fold 3 NDCG: 0.9727\n",
      "Fold 4 NDCG: 0.8350\n",
      "Fold 5 NDCG: 0.8016\n",
      "folds complete {'C': 0.01, 'tol': 0.0001, 'max_iter': 5000, 'penalty': 'l2', 'scores': [np.float64(0.8094), np.float64(0.4878), np.float64(0.9727), np.float64(0.835), np.float64(0.8016)], 'mean_score': np.float64(0.7813)}\n",
      "Fold 1 NDCG: 0.8094\n",
      "Fold 2 NDCG: 0.4878\n",
      "Fold 3 NDCG: 0.9727\n",
      "Fold 4 NDCG: 0.8350\n",
      "Fold 5 NDCG: 0.8016\n",
      "folds complete {'C': 100, 'tol': 0.0001, 'max_iter': 1000, 'penalty': 'l2', 'scores': [np.float64(0.8094), np.float64(0.4878), np.float64(0.9727), np.float64(0.835), np.float64(0.8016)], 'mean_score': np.float64(0.7813)}\n",
      "Fold 1 NDCG: 0.8094\n",
      "Fold 2 NDCG: 0.4878\n",
      "Fold 3 NDCG: 0.9727\n",
      "Fold 4 NDCG: 0.8350\n",
      "Fold 5 NDCG: 0.8016\n",
      "folds complete {'C': 100, 'tol': 0.0001, 'max_iter': 5000, 'penalty': 'l2', 'scores': [np.float64(0.8094), np.float64(0.4878), np.float64(0.9727), np.float64(0.835), np.float64(0.8016)], 'mean_score': np.float64(0.7813)}\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "scores = []\n",
    "\n",
    "for penalty in param_grid['penalty']:\n",
    "    for c in param_grid['C']:\n",
    "        for max_iter in param_grid['max_iter']:\n",
    "            for tol in param_grid['tol']:\n",
    "                fold_scores = []\n",
    "                for fold_idx, (train_idx, val_idx) in enumerate(gkf.split(X, y_2, group_ids)):\n",
    "\n",
    "                    # Get training and validation DataFrames\n",
    "                    X_train_fold = X_2[train_idx].copy()\n",
    "                    y_train_fold = y_2[train_idx].copy()\n",
    "                    X_val_fold = X_2[val_idx].copy()\n",
    "                    y_val_fold = y_2[val_idx].copy()\n",
    "                    \n",
    "                    # Create DataFrame for easier handling with session_id\n",
    "                    y_val_df_eval = pd.DataFrame({\n",
    "                        'label': y_val_fold[:, 0],\n",
    "                        'group': y_val_fold[:, 1]\n",
    "                    })\n",
    "\n",
    "                    # Fit and evaluate using calculate_ranking_ndcg\n",
    "                    fold_model = RankSVM(C=c, tol=tol, max_iter=max_iter, penalty=penalty, dual=False, random_state=42)\n",
    "                    fold_model.fit(X_train_fold, y_train_fold)\n",
    "                    preds = fold_model.predict(X_val_fold)\n",
    "                    y_val_df_eval['y_pred'] = preds\n",
    "                    fold_score = calculate_ranking_ndcg(y_val_df_eval.label,\n",
    "                                                       y_val_df_eval.y_pred,\n",
    "                                                       get_group_sizes(y_val_df_eval))\n",
    "\n",
    "                    fold_scores.append(round(fold_score,4))\n",
    "                    print(f\"Fold {fold_idx + 1} NDCG: {fold_score:.4f}\")\n",
    "                res = {'C': c, 'tol': tol, 'max_iter': max_iter, 'penalty':penalty, 'scores':fold_scores, 'mean_score':round(np.mean(fold_scores),4)}\n",
    "                results.append(res)\n",
    "                print ('folds complete', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch warnings becuase I don't want to publish the full file path of my installations\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ed062b",
   "metadata": {},
   "source": [
    "Compare to Pointwise Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "672b3a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 NDCG: 0.6530\n",
      "Fold 2 NDCG: 0.6649\n",
      "Fold 3 NDCG: 0.9822\n",
      "Fold 4 NDCG: 0.8284\n",
      "Fold 5 NDCG: 0.8832\n",
      "folds complete {'C': 0.01, 'tol': 0.0001, 'max_iter': 1000, 'penalty': 'l2', 'scores': [np.float64(0.653), np.float64(0.6649), np.float64(0.9822), np.float64(0.8284), np.float64(0.8832)], 'mean_score': np.float64(0.8023)}\n",
      "Fold 1 NDCG: 0.6530\n",
      "Fold 2 NDCG: 0.6649\n",
      "Fold 3 NDCG: 0.9822\n",
      "Fold 4 NDCG: 0.8284\n",
      "Fold 5 NDCG: 0.8832\n",
      "folds complete {'C': 0.01, 'tol': 0.0001, 'max_iter': 5000, 'penalty': 'l2', 'scores': [np.float64(0.653), np.float64(0.6649), np.float64(0.9822), np.float64(0.8284), np.float64(0.8832)], 'mean_score': np.float64(0.8023)}\n",
      "Fold 1 NDCG: 0.6606\n",
      "Fold 2 NDCG: 0.7260\n",
      "Fold 3 NDCG: 0.9822\n",
      "Fold 4 NDCG: 0.8488\n",
      "Fold 5 NDCG: 0.7189\n",
      "folds complete {'C': 100, 'tol': 0.0001, 'max_iter': 1000, 'penalty': 'l2', 'scores': [np.float64(0.6606), np.float64(0.726), np.float64(0.9822), np.float64(0.8488), np.float64(0.7189)], 'mean_score': np.float64(0.7873)}\n",
      "Fold 1 NDCG: 0.6606\n",
      "Fold 2 NDCG: 0.7260\n",
      "Fold 3 NDCG: 0.9822\n",
      "Fold 4 NDCG: 0.8488\n",
      "Fold 5 NDCG: 0.7189\n",
      "folds complete {'C': 100, 'tol': 0.0001, 'max_iter': 5000, 'penalty': 'l2', 'scores': [np.float64(0.6606), np.float64(0.726), np.float64(0.9822), np.float64(0.8488), np.float64(0.7189)], 'mean_score': np.float64(0.7873)}\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "scores = []\n",
    "\n",
    "for penalty in param_grid['penalty']:\n",
    "    for c in param_grid['C']:\n",
    "        for max_iter in param_grid['max_iter']:\n",
    "            for tol in param_grid['tol']:\n",
    "                fold_scores = []\n",
    "                for fold_idx, (train_idx, val_idx) in enumerate(gkf.split(X, y_2, group_ids)):\n",
    "\n",
    "                    # Get training and validation DataFrames\n",
    "                    X_train_fold = X[train_idx].copy()\n",
    "                    y_train_fold = y[train_idx].copy()\n",
    "                    X_val_fold = X[val_idx].copy()\n",
    "                    y_val_fold = y[val_idx].copy()\n",
    "                    \n",
    "                    # Create DataFrame for easier handling with grouping/query parameter\n",
    "                    y_val_df_eval_pointwise = pd.DataFrame({\n",
    "                        'label': y_2[val_idx, 0],\n",
    "                        'group': y_2[val_idx, 1]\n",
    "                    })\n",
    "\n",
    "                    # Fit and evaluate using calculate_ranking_ndcg\n",
    "                    fold_model = svm.LinearSVC(C=c, tol=tol, max_iter=max_iter, penalty=penalty, dual=False, random_state=42)\n",
    "                    fold_model.fit(X_train_fold, y_train_fold)\n",
    "                    y_val_df_eval_pointwise['y_pred'] = get_group_rankings(fold_model, X_val_fold, y_2[val_idx, 1])\n",
    "                    fold_score = calculate_ranking_ndcg(y_val_df_eval_pointwise.label,\n",
    "                                                       y_val_df_eval_pointwise.y_pred,\n",
    "                                                       get_group_sizes(y_val_df_eval_pointwise))\n",
    "\n",
    "                    fold_scores.append(round(fold_score,4))\n",
    "                    print(f\"Fold {fold_idx + 1} NDCG: {fold_score:.4f}\")\n",
    "                res = {'C': c, 'tol': tol, 'max_iter': max_iter, 'penalty':penalty, 'scores':fold_scores, 'mean_score':round(np.mean(fold_scores),4)}\n",
    "                results.append(res)\n",
    "                print ('folds complete', res)\n",
    "prediction = fold_model.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ranksvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
